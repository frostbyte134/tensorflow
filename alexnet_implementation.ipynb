{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexnet_implementation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nailbrainz/tensorflow/blob/master/alexnet_implementation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YRnZQjzlr4xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e4cfe8f-0d8f-4c46-9951-ecf877e4a12c"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos]\n",
        "print(get_available_gpus())\n",
        "\n",
        "\n",
        "print(\"packs loaded\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/device:CPU:0', '/device:GPU:0']\n",
            "packs loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1nW6nqUVr_WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d7621f70-8962-4630-d86f-265442bf721c"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('data/', one_hot=True)\n",
        "trainimg   = mnist.train.images\n",
        "trainlabel = mnist.train.labels\n",
        "testimg    = mnist.test.images\n",
        "testlabel  = mnist.test.labels\n",
        "randidx = np.random.randint(testimg.shape[0], size=150)\n",
        "print(type(testimg))\n",
        "print(testimg.shape)\n",
        "testimg = testimg[randidx, :]\n",
        "testlabel = testlabel[randidx, :]\n",
        "print(type(testimg))\n",
        "print(testimg.shape)\n",
        "print(type(trainimg))\n",
        "print(trainimg.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "<class 'numpy.ndarray'>\n",
            "(10000, 784)\n",
            "<class 'numpy.ndarray'>\n",
            "(150, 784)\n",
            "<class 'numpy.ndarray'>\n",
            "(55000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbTot47DE6sV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initial_padding(im):\n",
        "  ret = np.zeros([227, 227, 3])\n",
        "  ret[1:226][1:226][:] = im[:][:][:]\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_3VwskYE3Gm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Network Building"
      ]
    },
    {
      "metadata": {
        "id": "BY5otoOtsF_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46f85ae6-1251-45b5-86a0-5647d1aa1eac"
      },
      "cell_type": "code",
      "source": [
        "n_input = trainimg.shape[1]\n",
        "print(trainimg.shape)\n",
        "n_output = trainlabel.shape[1]\n",
        "_input_r = tf.reshape(trainimg, shape=[-1, 28, 28, 1])\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, n_input])\n",
        "y = tf.placeholder(tf.float32, [None, n_output])\n",
        "keepratio = tf.placeholder(tf.float32)\n",
        "\n",
        "stdev = 0.01\n",
        "devicetype = \"/gpu:0\"\n",
        "with tf.device(devicetype):\n",
        "  ws = {\n",
        "      \"conv1_w1\":tf.Variable(tf.truncated_normal([11, 11, 3, 48], stddev=stdev)),\n",
        "      \"conv1_w2\":tf.Variable(tf.truncated_normal([11, 11, 3, 48], stddev=stdev)),\n",
        "      \"conv2_w1\":tf.Variable(tf.truncated_normal([5, 5, 48, 128], stddev=stdev)),\n",
        "      \"conv2_w2\":tf.Variable(tf.truncated_normal([5, 5, 48, 128], stddev=stdev)),\n",
        "      \"conv3_w1\":tf.Variable(tf.truncated_normal([3, 3, 256, 192], stddev=stdev)),\n",
        "      \"conv3_w2\":tf.Variable(tf.truncated_normal([3, 3, 256, 192], stddev=stdev)),\n",
        "      \"conv4_w1\":tf.Variable(tf.truncated_normal([3, 3, 192, 192], stddev=stdev)),\n",
        "      \"conv4_w2\":tf.Variable(tf.truncated_normal([3, 3, 192, 192], stddev=stdev)),\n",
        "      \"conv5_w1\":tf.Variable(tf.truncated_normal([3, 3, 192, 128], stddev=stdev)),\n",
        "      \"conv5_w2\":tf.Variable(tf.truncated_normal([3, 3, 192, 128], stddev=stdev)),\n",
        "      \"fc1_w\":tf.Variable(tf.truncated_normal([(11*11*128*2), 4096], stddev=stdev)),\n",
        "      \"fc2_w\":tf.Variable(tf.truncated_normal([4096, 4096], stddev=stdev)),\n",
        "      \"fc3_w\":tf.Variable(tf.truncated_normal([4096, 1024], stddev=stdev))\n",
        "  }\n",
        "  bs = {\n",
        "      \"conv1_b1\":tf.Variable(tf.zeros([48])),\n",
        "      \"conv1_b2\":tf.Variable(tf.zeros([48])),\n",
        "      \"conv2_b1\":tf.Variable(tf.ones([128])),\n",
        "      \"conv2_b2\":tf.Variable(tf.ones([128])),\n",
        "      \"conv3_b1\":tf.Variable(tf.zeros([48])),\n",
        "      \"conv3_b2\":tf.Variable(tf.zeros([48])),\n",
        "      \"conv4_b1\":tf.Variable(tf.ones([192])),\n",
        "      \"conv4_b2\":tf.Variable(tf.ones([192])),\n",
        "      \"conv5_b1\":tf.Variable(tf.ones([192])),\n",
        "      \"conv5_b2\":tf.Variable(tf.ones([192])),\n",
        "      \"fc1_b\":tf.Variable(tf.ones([4096])),\n",
        "      \"fc2_b\":tf.Variable(tf.ones([4096])),\n",
        "      \"fc3_b\":tf.Variable(tf.ones([1024]))\n",
        "  }\n",
        "  \n",
        "  def conv_layer(_layer, _idx, _prevs, _w, _b, _strides, _pad):\n",
        "    tmp = tf.nn.conv2d(_prevs, _w['conv'+str(_layer)+'_w'+str(_idx)], strides=_strides, padding=_pad)\n",
        "    tmp = tf.add(conv1_1, _w['conv'+str(_layer)+'_b'+str(_idx)])\n",
        "    tmp = tf.nn.relu(tmp)\n",
        "    return tmp\n",
        "    \n",
        "  def resp_normalization(_input, N, C):\n",
        "    n = 5\n",
        "    k = 2\n",
        "    alp = 10e-4\n",
        "    beta = 0.75\n",
        "    for g in range(1, 3):\n",
        "      for i in range(C):\n",
        "        for x in range(N):\n",
        "          for y in range(N):\n",
        "            a1 = 0\n",
        "            for j in range(max(0, i-n/2), min(C-1, i+n/2)):\n",
        "              a1 += _input[g][x][y][j]**2\n",
        "            a1 = (k + a1)**beta\n",
        "            _input[g][x][y][i] /= a1 \n",
        "  \n",
        "  def conv_construct(_input, _w, _b, _ratio):\n",
        "    #input\n",
        "    #(227 X 227 X 3)\n",
        "    \n",
        "    #conv1\n",
        "    conv1_1 = conv_layer(1, 1, _input, _w, _b, [1, 4, 4, 1], \"VALID\")\n",
        "    conv1_2 = conv_layer(1, 2, _input, _w, _b, [1, 4, 4, 1], \"VALID\")\n",
        "    # (55 X 55 X 48) X 2\n",
        "    conv1_1 = tf.nn.max_pool(conv1_1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv1_2 = tf.nn.max_pool(conv1_2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv1_1, conv1_2 = resp_normalization([conv1_1, conv1_2], 55, 48)\n",
        "    conv1_1 = tf.nn.dropout(conv1_1, _ratio)\n",
        "    conv1_2 = tf.nn.dropout(conv1_2, _ratio)\n",
        "    # (27 X 27 X 48) X 2\n",
        "    \n",
        "    #conv2\n",
        "    conv2_1 = conv_layer(2, 1, conv1_1, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    conv2_2 = conv_layer(2, 2, conv1_2, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    # (27 X 27 X 128) X 2\n",
        "    conv2_1 = tf.nn.max_pool(conv1_1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv2_2 = tf.nn.max_pool(conv1_2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv2_1, conv2_2 = resp_normalization([conv2_1, conv2_2], N=27, C=128)\n",
        "    conv2_1 = tf.nn.dropout(conv2_1, _ratio)\n",
        "    conv2_2 = tf.nn.dropout(conv2_2, _ratio)\n",
        "    # (27 X 27 X 48) X 2\n",
        "    \n",
        "    #conv3\n",
        "    conv3_input = tf.contat([conv2_1, conv2_2], 2)\n",
        "    conv3_1 = conv_layer(3, 1, conv3_input, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    conv3_2 = conv_layer(3, 2, conv3_input, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    # (13 X 13 X 192) X 2\n",
        "    conv3_1 = tf.nn.dropout(conv3_1, _ratio)\n",
        "    conv3_2 = tf.nn.dropout(conv3_2, _ratio)\n",
        "    # (13 X 13 X 192) X 2\n",
        "    \n",
        "    #conv4\n",
        "    conv4_1 = conv_layer(4, 1, conv3_input, _w, _b, [1, 4, 4, 1], \"SAME\")\n",
        "    conv4_2 = conv_layer(4, 2, conv3_input, _w, _b, [1, 4, 4, 1], \"SAME\")\n",
        "    # (13 X 13 X 192) X 2\n",
        "    conv4_1 = tf.nn.dropout(conv4_1, _ratio)\n",
        "    conv4_2 = tf.nn.dropout(conv4_2, _ratio)\n",
        "    # (13 X 13 X 192) X 2\n",
        "    \n",
        "    #conv5\n",
        "    conv5_1 = conv_layer(5, 1, conv3_input, _w, _b, [1, 4, 4, 1], \"SAME\")\n",
        "    conv5_2 = conv_layer(5, 2, conv3_input, _w, _b, [1, 4, 4, 1], \"SAME\")\n",
        "    # (13 X 13 X 128) X 2\n",
        "    conv5_1 = tf.nn.dropout(conv5_1, _ratio)\n",
        "    conv5_2 = tf.nn.dropout(conv5_2, _ratio)\n",
        "    conv5_1 = tf.nn.max_pool(conv5_1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv5_2 = tf.nn.max_pool(conv5_2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    # (11 X 11 X 128 ) X 2\n",
        "    \n",
        "    \n",
        "    fc6_input = tf.contat([conv5_1, conv5_2], 2)\n",
        "    fc6 = tf.nn.relu(tf.add(tf.matmul(fc6_input, _w['fc1_w']), _b['fc1_b'])) \n",
        "    fc7 = tf.nn.relu(tf.add(tf.matmul(fc6, _w['fc2_w']), _b['fc2_b'])) \n",
        "    fc8 = tf.nn.relu(tf.add(tf.matmul(fc7, _w['fc3_w']), _b['fc3_b'])) \n",
        "    return fc8    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NUWbcjowEz8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7uf3scRg2g5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f4046cf5-131f-49c9-fd2c-cd5cb027f949"
      },
      "cell_type": "code",
      "source": [
        "keepratio = tf.placeholder(tf.float32)\n",
        "with tf.device(devicetype):\n",
        "  pred = conv_construct(x, ws, bs, keepratio)\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
        "  optm = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
        "  corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "  accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
        "  init = tf.initialize_all_variables()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-0f03ae15b204>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HGEPfwGm7NdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_config = tf.ConfigProto(allow_soft_placement=True)\n",
        "sess = tf.Session(config=_config)\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PudwXohi-ykp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "6d76e896-84a2-456f-9a65-b26567687a31"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "training_epochs = 15\n",
        "batch_size = 50\n",
        "display_step = 1\n",
        "do_train = 1\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  total_batch = int(mnist.train.num_examples/batch_size)\n",
        "  avg_cost = 0\n",
        "  for i in range(total_batch):\n",
        "    b_x, b_y = mnist.train.next_batch(batch_size)\n",
        "    fds = {x:b_x, y:b_y, keepratio:0.7}\n",
        "    sess.run(optm, feed_dict=fds)\n",
        "    avg_cost += sess.run(cost, feed_dict=fds)\n",
        "  avg_cost /= total_batch\n",
        "  \n",
        "  if(epoch % display_step == 0):\n",
        "    print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
        "    train_acc = sess.run(accr, feed_dict={x:b_x, y:b_y, keepratio:1.})\n",
        "    print (\" Training accuracy: %.3f\" % (train_acc))\n",
        "    test_acc = sess.run(accr, feed_dict={x:testimg, y:testlabel, keepratio:1.})\n",
        "    print (\" Test accuracy: %.3f\" % (test_acc))\n",
        "\n",
        "print (\"OPTIMIZATION FINISHED\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 000/015 cost: 4.167287400\n",
            " Training accuracy: 0.960\n",
            " Test accuracy: 0.953\n",
            "Epoch: 001/015 cost: 0.080709929\n",
            " Training accuracy: 0.980\n",
            " Test accuracy: 0.967\n",
            "Epoch: 002/015 cost: 0.063318245\n",
            " Training accuracy: 0.960\n",
            " Test accuracy: 0.993\n",
            "Epoch: 003/015 cost: 0.055270068\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.993\n",
            "Epoch: 004/015 cost: 0.043149504\n",
            " Training accuracy: 0.980\n",
            " Test accuracy: 0.987\n",
            "Epoch: 005/015 cost: 0.034015307\n",
            " Training accuracy: 0.960\n",
            " Test accuracy: 0.980\n",
            "Epoch: 006/015 cost: 0.026027571\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.987\n",
            "Epoch: 007/015 cost: 0.020174158\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.987\n",
            "Epoch: 008/015 cost: 0.017992473\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.993\n",
            "Epoch: 009/015 cost: 0.014687875\n",
            " Training accuracy: 0.980\n",
            " Test accuracy: 1.000\n",
            "Epoch: 010/015 cost: 0.012599613\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.973\n",
            "Epoch: 011/015 cost: 0.010864377\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.993\n",
            "Epoch: 012/015 cost: 0.009880823\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 1.000\n",
            "Epoch: 013/015 cost: 0.009277123\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.980\n",
            "Epoch: 014/015 cost: 0.007941424\n",
            " Training accuracy: 1.000\n",
            " Test accuracy: 0.987\n",
            "OPTIMIZATION FINISHED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2pSjg2yDFN4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}