{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexnet_implementation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nailbrainz/tensorflow/blob/master/alexnet_implementation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YRnZQjzlr4xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "04908990-cace-4035-8196-13795399b99a"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos]\n",
        "print(get_available_gpus())\n",
        "\n",
        "\n",
        "print(\"packs loaded\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/device:CPU:0', '/device:GPU:0']\n",
            "packs loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1nW6nqUVr_WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4e25674d-c83d-40e9-af1f-4a2371868fdd"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('data/', one_hot=True)\n",
        "trainimg   = mnist.train.images\n",
        "trainlabel = mnist.train.labels\n",
        "testimg    = mnist.test.images\n",
        "testlabel  = mnist.test.labels\n",
        "randidx = np.random.randint(testimg.shape[0], size=150)\n",
        "print(type(testimg))\n",
        "print(testimg.shape)\n",
        "testimg = testimg[randidx, :]\n",
        "testlabel = testlabel[randidx, :]\n",
        "print(type(testimg))\n",
        "print(testimg.shape)\n",
        "print(type(trainimg))\n",
        "print(trainimg.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "<class 'numpy.ndarray'>\n",
            "(10000, 784)\n",
            "<class 'numpy.ndarray'>\n",
            "(150, 784)\n",
            "<class 'numpy.ndarray'>\n",
            "(55000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbTot47DE6sV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initial_padding(im):\n",
        "  ret = np.zeros([227, 227, 3])\n",
        "  ret[1:226][1:226][:] = im[:][:][:]\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_3VwskYE3Gm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Network Building"
      ]
    },
    {
      "metadata": {
        "id": "BY5otoOtsF_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a008e3e-86fa-4631-9ba2-9657512ecaa1"
      },
      "cell_type": "code",
      "source": [
        "n_input = trainimg.shape[1]\n",
        "print(trainimg.shape)\n",
        "n_output = trainlabel.shape[1]\n",
        "_input_r = tf.reshape(trainimg, shape=[-1, 28, 28, 1])\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 227, 227, 3])\n",
        "y = tf.placeholder(tf.float32, [None, 1000])\n",
        "keepratio = tf.placeholder(tf.float32)\n",
        "\n",
        "stdev = 0.01\n",
        "devicetype = \"/gpu:0\"\n",
        "with tf.device(devicetype):\n",
        "  ws = {\n",
        "      \"conv1_w1\":tf.Variable(tf.truncated_normal([11, 11, 3, 48], stddev=stdev)),\n",
        "      \"conv1_w2\":tf.Variable(tf.truncated_normal([11, 11, 3, 48], stddev=stdev)),\n",
        "      \"conv2_w1\":tf.Variable(tf.truncated_normal([5, 5, 48, 128], stddev=stdev)),\n",
        "      \"conv2_w2\":tf.Variable(tf.truncated_normal([5, 5, 48, 128], stddev=stdev)),\n",
        "      \"conv3_w1\":tf.Variable(tf.truncated_normal([3, 3, 256, 192], stddev=stdev)),\n",
        "      \"conv3_w2\":tf.Variable(tf.truncated_normal([3, 3, 256, 192], stddev=stdev)),\n",
        "      \"conv4_w1\":tf.Variable(tf.truncated_normal([3, 3, 192, 192], stddev=stdev)),\n",
        "      \"conv4_w2\":tf.Variable(tf.truncated_normal([3, 3, 192, 192], stddev=stdev)),\n",
        "      \"conv5_w1\":tf.Variable(tf.truncated_normal([3, 3, 192, 128], stddev=stdev)),\n",
        "      \"conv5_w2\":tf.Variable(tf.truncated_normal([3, 3, 192, 128], stddev=stdev)),\n",
        "      \"fc1_w\":tf.Variable(tf.truncated_normal([(6*6*128*2), 4096], stddev=stdev)),\n",
        "      \"fc2_w\":tf.Variable(tf.truncated_normal([4096, 4096], stddev=stdev)),\n",
        "      \"fc3_w\":tf.Variable(tf.truncated_normal([4096, 1024], stddev=stdev))\n",
        "  }\n",
        "  bs = {\n",
        "      \"conv1_b1\":tf.Variable(tf.zeros([48])),\n",
        "      \"conv1_b2\":tf.Variable(tf.zeros([48])),\n",
        "      \"conv2_b1\":tf.Variable(tf.ones([128])),\n",
        "      \"conv2_b2\":tf.Variable(tf.ones([128])),\n",
        "      \"conv3_b1\":tf.Variable(tf.zeros([192])),\n",
        "      \"conv3_b2\":tf.Variable(tf.zeros([192])),\n",
        "      \"conv4_b1\":tf.Variable(tf.ones([192])),\n",
        "      \"conv4_b2\":tf.Variable(tf.ones([192])),\n",
        "      \"conv5_b1\":tf.Variable(tf.ones([128])),\n",
        "      \"conv5_b2\":tf.Variable(tf.ones([128])),\n",
        "      \"fc1_b\":tf.Variable(tf.ones([4096])),\n",
        "      \"fc2_b\":tf.Variable(tf.ones([4096])),\n",
        "      \"fc3_b\":tf.Variable(tf.ones([1024]))\n",
        "  }\n",
        "  \n",
        "  def conv_layer(_layer, _idx, _prevs, _w, _b, _strides, _pad):\n",
        "    tmp = tf.nn.conv2d(_prevs, _w['conv'+str(_layer)+'_w'+str(_idx)], strides=_strides, padding=_pad)\n",
        "    tmp = tf.add(tmp, _b['conv'+str(_layer)+'_b'+str(_idx)])\n",
        "    tmp = tf.nn.relu(tmp)\n",
        "    return tmp\n",
        "    \n",
        "  def resp_normalization(_input, N, C):\n",
        "    n = 5\n",
        "    k = 2\n",
        "    alp = 10e-4\n",
        "    beta = 0.75\n",
        "    for g in range(1, 3):\n",
        "      for i in range(C):\n",
        "        for x in range(N):\n",
        "          for y in range(N):\n",
        "            a1 = 0\n",
        "            for j in range(max(0, int(i-n/2)), min(C-1, i+int(n/2))):\n",
        "              a1 += _input[g][x][y][j]**2\n",
        "            a1 = (k + a1)**beta\n",
        "            #_input[g][x][y][i].assign(_input[g][x][y][i]/a1)  \n",
        "  \n",
        "  def conv_construct(_input, _w, _b, _ratio):\n",
        "    #input\n",
        "    #(227 X 227 X 3)\n",
        "    \n",
        "    #conv1\n",
        "    conv1_1 = conv_layer(1, 1, _input, _w, _b, [1, 4, 4, 1], \"VALID\")\n",
        "    conv1_2 = conv_layer(1, 2, _input, _w, _b, [1, 4, 4, 1], \"VALID\")\n",
        "    # (55 X 55 X 48) X 2\n",
        "    conv1_1 = tf.nn.max_pool(conv1_1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv1_2 = tf.nn.max_pool(conv1_2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    #conv1_1, conv1_2 = resp_normalization([conv1_1, conv1_2], 55, 48)\n",
        "    conv1_1 = tf.nn.dropout(conv1_1, _ratio)\n",
        "    conv1_2 = tf.nn.dropout(conv1_2, _ratio)\n",
        "    # (27 X 27 X 48) X 2\n",
        "    \n",
        "    #conv2\n",
        "    conv2_1 = conv_layer(2, 1, conv1_1, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    conv2_2 = conv_layer(2, 2, conv1_2, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    # (27 X 27 X 128) X 2\n",
        "    conv2_1 = tf.nn.max_pool(conv2_1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv2_2 = tf.nn.max_pool(conv2_2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    #conv2_1, conv2_2 = resp_normalization([conv2_1, conv2_2], N=27, C=128)\n",
        "    conv2_1 = tf.nn.dropout(conv2_1, _ratio)\n",
        "    conv2_2 = tf.nn.dropout(conv2_2, _ratio)\n",
        "    # (13 X 13 X 128) X 2\n",
        "    \n",
        "    #conv3\n",
        "    conv3_input = tf.concat([conv2_1, conv2_2], 3)\n",
        "    conv3_1 = conv_layer(3, 1, conv3_input, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    conv3_2 = conv_layer(3, 2, conv3_input, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    # (13 X 13 X 192) X 2\n",
        "    conv3_1 = tf.nn.dropout(conv3_1, _ratio)\n",
        "    conv3_2 = tf.nn.dropout(conv3_2, _ratio)\n",
        "    # (13 X 13 X 192) X 2\n",
        "    \n",
        "    #conv4\n",
        "    conv4_1 = conv_layer(4, 1, conv3_1, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    conv4_2 = conv_layer(4, 2, conv3_2, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    # (13 X 13 X 192) X 2\n",
        "    conv4_1 = tf.nn.dropout(conv4_1, _ratio)\n",
        "    conv4_2 = tf.nn.dropout(conv4_2, _ratio)\n",
        "    # (13 X 13 X 192) X 2\n",
        "    \n",
        "    #conv5\n",
        "    conv5_1 = conv_layer(5, 1, conv4_1, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    conv5_2 = conv_layer(5, 2, conv4_2, _w, _b, [1, 1, 1, 1], \"SAME\")\n",
        "    print(conv5_1.get_shape())\n",
        "    # (13 X 13 X 128) X 2\n",
        "    conv5_1 = tf.nn.dropout(conv5_1, _ratio)\n",
        "    conv5_2 = tf.nn.dropout(conv5_2, _ratio)\n",
        "    conv5_1 = tf.nn.max_pool(conv5_1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    conv5_2 = tf.nn.max_pool(conv5_2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    # (11 X 11 X 128 ) X 2\n",
        "    \n",
        "    \n",
        "    print(conv5_2.get_shape())\n",
        "    fc6_input = tf.concat([conv5_1, conv5_2], 3)\n",
        "    print(fc6_input.get_shape())\n",
        "    \n",
        "    fc6_input = tf.reshape(conv5_1, [-1, int(np.prod(fc6_input.get_shape()[1:]))])\n",
        "    fc6 = tf.nn.relu(tf.add(tf.matmul(fc6_input, _w['fc1_w']), _b['fc1_b'])) \n",
        "    fc7 = tf.nn.relu(tf.add(tf.matmul(fc6, _w['fc2_w']), _b['fc2_b'])) \n",
        "    fc8 = tf.nn.relu(tf.add(tf.matmul(fc7, _w['fc3_w']), _b['fc3_b'])) \n",
        "    return fc8    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NUWbcjowEz8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7uf3scRg2g5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5db14e7c-0f75-4ed3-cb1b-76c7855dd309"
      },
      "cell_type": "code",
      "source": [
        "keepratio = tf.placeholder(tf.float32)\n",
        "with tf.device(devicetype):\n",
        "  pred = conv_construct(x, ws, bs, keepratio)\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
        "  optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "  corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "  accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
        "  init = tf.initialize_all_variables()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 13, 13, 128)\n",
            "(?, 6, 6, 128)\n",
            "(?, 6, 6, 256)\n",
            "WARNING:tensorflow:From <ipython-input-5-bdec6c4fff02>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HGEPfwGm7NdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_config = tf.ConfigProto() #allow_soft_placement=True\n",
        "sess = tf.Session(config=_config)\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PudwXohi-ykp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "fbc910df-2e89-4d3d-d1ec-b34d5d8bceb9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "training_epochs = 15\n",
        "batch_size = 50\n",
        "display_step = 1\n",
        "do_train = 1\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  total_batch = int(mnist.train.num_examples/batch_size)\n",
        "  avg_cost = 0\n",
        "  for i in range(total_batch):\n",
        "    b_x, b_y = mnist.train.next_batch(batch_size)\n",
        "    fds = {x:b_x, y:b_y, keepratio:0.7}\n",
        "    sess.run(optm, feed_dict=fds)\n",
        "    avg_cost += sess.run(cost, feed_dict=fds)\n",
        "  avg_cost /= total_batch\n",
        "  \n",
        "  if(epoch % display_step == 0):\n",
        "    print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
        "    train_acc = sess.run(accr, feed_dict={x:b_x, y:b_y, keepratio:1.})\n",
        "    print (\" Training accuracy: %.3f\" % (train_acc))\n",
        "    test_acc = sess.run(accr, feed_dict={x:testimg, y:testlabel, keepratio:1.})\n",
        "    print (\" Test accuracy: %.3f\" % (test_acc))\n",
        "\n",
        "print (\"OPTIMIZATION FINISHED\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-df5f610987ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mb_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepratio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mavg_cost\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1113\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1114\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (50, 784) for Tensor 'Placeholder:0', which has shape '(?, 227, 227, 3)'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2pSjg2yDFN4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}